{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPsRjuDtCfL+KC0/pbmVdz/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/virtualspark/YCNG232-NLP_Fundamentals/blob/main/Reflexion_Week_8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import string\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.cluster import KMeans"
      ],
      "metadata": {
        "id": "qA16AQzMUwkE"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reference: https://github.com/MihailSalnikov/tf-idf_and_k-means/blob/master/main.ipynb\n",
        "# https://medium.com/@MSalnikov/text-clustering-with-k-means-and-tf-idf-f099bcf95183\n",
        "# https://medium.com/mlearning-ai/text-clustering-with-tf-idf-in-python-c94cd26a31e7"
      ],
      "metadata": {
        "id": "tEDnTW7IacZ8"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "593UBZ0gacW7"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_text = \"\"\"\n",
        "Google and Facebook are strangling the free press to death. Democracy is the loser\n",
        "Your 60-second guide to security stuff Google touted today at Next '18\n",
        "A Guide to Using Android Without Selling Your Soul to Google\n",
        "Review: Lenovo’s Google Smart Display is pretty and intelligent\n",
        "Google Maps user spots mysterious object submerged off the coast of Greece - and no-one knows what it is\n",
        "Android is better than IOS\n",
        "In information retrieval, tf–idf or TFIDF, short for term frequency–inverse document frequency\n",
        "is a numerical statistic that is intended to reflect\n",
        "how important a word is to a document in a collection or corpus.\n",
        "It is often used as a weighting factor in searches of information retrieval\n",
        "text mining, and user modeling. The tf-idf value increases proportionally\n",
        "to the number of times a word appears in the document\n",
        "and is offset by the frequency of the word in the corpus\n",
        "\"\"\".split(\"\\n\")[1:-1]"
      ],
      "metadata": {
        "id": "tp4wKtVmWouI"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sEWuDyjVXQwV",
        "outputId": "f960bf7b-a6a2-402d-8313-6f6cff65de48"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Google and Facebook are strangling the free press to death. Democracy is the loser',\n",
              " \"Your 60-second guide to security stuff Google touted today at Next '18\",\n",
              " 'A Guide to Using Android Without Selling Your Soul to Google',\n",
              " 'Review: Lenovo’s Google Smart Display is pretty and intelligent',\n",
              " 'Google Maps user spots mysterious object submerged off the coast of Greece - and no-one knows what it is',\n",
              " 'Android is better than IOS',\n",
              " 'In information retrieval, tf–idf or TFIDF, short for term frequency–inverse document frequency',\n",
              " 'is a numerical statistic that is intended to reflect',\n",
              " 'how important a word is to a document in a collection or corpus.',\n",
              " 'It is often used as a weighting factor in searches of information retrieval',\n",
              " 'text mining, and user modeling. The tf-idf value increases proportionally',\n",
              " 'to the number of times a word appears in the document',\n",
              " 'and is offset by the frequency of the word in the corpus']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessing and tokenizing\n",
        "def preprocessing(line):\n",
        "    line = line.lower()\n",
        "    line = re.sub(r\"[{}]\".format(string.punctuation), \" \", line)\n",
        "    return line"
      ],
      "metadata": {
        "id": "Af-mPQNYXhaM"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dWTFxJoiRicP"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TD-IDF"
      ],
      "metadata": {
        "id": "Km1ZiIOmRjgH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf_vectorizer = TfidfVectorizer(preprocessor=preprocessing)"
      ],
      "metadata": {
        "id": "EYb5ase_YCbz"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf = tfidf_vectorizer.fit_transform(all_text)"
      ],
      "metadata": {
        "id": "b-zsouHNYEV7"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kmeans = KMeans(n_clusters=2).fit(tfidf)"
      ],
      "metadata": {
        "id": "Qric6FRiYFjK"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lines_for_predicting = [\"Google and Facebook are strangling the free press to death. Democracy is the loser\", \"Your 60-second guide to security stuff Google touted today at Next '18\"]\n",
        "predicted = kmeans.predict(tfidf_vectorizer.transform(lines_for_predicting))"
      ],
      "metadata": {
        "id": "Z3mHBXQvZJaZ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import rand_score"
      ],
      "metadata": {
        "id": "v-Uu6kRVZLxZ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rand_score(lines_for_predicting, predicted)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GrNoA9wWZN-y",
        "outputId": "e5311f64-b40d-44b8-f3ee-2f05da516e3c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "E51w_-FyaG-L"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "PMI"
      ],
      "metadata": {
        "id": "0NQj1jAkRr6w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.collocations import *\n",
        "from nltk.tokenize import word_tokenize"
      ],
      "metadata": {
        "id": "8xGB5RUwdaNq"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eCfrIDeqduTe",
        "outputId": "bc00cd72-f3c8-4fc6-f999-7718134f3c89"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Google and Facebook are strangling the free press to death. Democracy is the loser Your 60-second guide to security stuff Google touted today at Next '18 A Guide to Using Android Without Selling Your Soul to Google\""
      ],
      "metadata": {
        "id": "b-ApB_hRdyO8"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bigram_measures = nltk.collocations.BigramAssocMeasures()\n",
        "finder = BigramCollocationFinder.from_words(word_tokenize(text))"
      ],
      "metadata": {
        "id": "sJNG5qnLdJfN"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in finder.score_ngrams(bigram_measures.pmi):\n",
        "  print (i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5KBftCpTdNC1",
        "outputId": "0e3b2e22-049a-4618-953e-e84f345e38cc"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "((\"'18\", 'A'), 5.247927513443585)\n",
            "(('.', 'Democracy'), 5.247927513443585)\n",
            "(('60-second', 'guide'), 5.247927513443585)\n",
            "(('A', 'Guide'), 5.247927513443585)\n",
            "(('Android', 'Without'), 5.247927513443585)\n",
            "(('Democracy', 'is'), 5.247927513443585)\n",
            "(('Facebook', 'are'), 5.247927513443585)\n",
            "(('Next', \"'18\"), 5.247927513443585)\n",
            "(('Using', 'Android'), 5.247927513443585)\n",
            "(('Without', 'Selling'), 5.247927513443585)\n",
            "(('and', 'Facebook'), 5.247927513443585)\n",
            "(('are', 'strangling'), 5.247927513443585)\n",
            "(('at', 'Next'), 5.247927513443585)\n",
            "(('death', '.'), 5.247927513443585)\n",
            "(('free', 'press'), 5.247927513443585)\n",
            "(('security', 'stuff'), 5.247927513443585)\n",
            "(('today', 'at'), 5.247927513443585)\n",
            "(('touted', 'today'), 5.247927513443585)\n",
            "(('Selling', 'Your'), 4.247927513443585)\n",
            "(('Your', '60-second'), 4.247927513443585)\n",
            "(('Your', 'Soul'), 4.247927513443585)\n",
            "(('is', 'the'), 4.247927513443585)\n",
            "(('loser', 'Your'), 4.247927513443585)\n",
            "(('strangling', 'the'), 4.247927513443585)\n",
            "(('the', 'free'), 4.247927513443585)\n",
            "(('the', 'loser'), 4.247927513443585)\n",
            "(('Google', 'and'), 3.662965012722429)\n",
            "(('Google', 'touted'), 3.662965012722429)\n",
            "(('stuff', 'Google'), 3.662965012722429)\n",
            "(('Guide', 'to'), 3.247927513443585)\n",
            "(('Soul', 'to'), 3.247927513443585)\n",
            "(('guide', 'to'), 3.247927513443585)\n",
            "(('press', 'to'), 3.247927513443585)\n",
            "(('to', 'Using'), 3.247927513443585)\n",
            "(('to', 'death'), 3.247927513443585)\n",
            "(('to', 'security'), 3.247927513443585)\n",
            "(('to', 'Google'), 1.6629650127224291)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Jvj7ZdN-d-yH"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trigram_measures = nltk.collocations.TrigramAssocMeasures()\n",
        "finder = TrigramCollocationFinder.from_words(word_tokenize(text))"
      ],
      "metadata": {
        "id": "PCWOykfrS-_W"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in finder.score_ngrams(trigram_measures.pmi):\n",
        "  print (i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-4vEi_eBS-80",
        "outputId": "d966559e-3d9d-4d70-dc5e-16acca7ffa5d"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "((\"'18\", 'A', 'Guide'), 10.49585502688717)\n",
            "(('.', 'Democracy', 'is'), 10.49585502688717)\n",
            "(('Android', 'Without', 'Selling'), 10.49585502688717)\n",
            "(('Facebook', 'are', 'strangling'), 10.49585502688717)\n",
            "(('Next', \"'18\", 'A'), 10.49585502688717)\n",
            "(('Using', 'Android', 'Without'), 10.49585502688717)\n",
            "(('and', 'Facebook', 'are'), 10.49585502688717)\n",
            "(('at', 'Next', \"'18\"), 10.49585502688717)\n",
            "(('death', '.', 'Democracy'), 10.49585502688717)\n",
            "(('today', 'at', 'Next'), 10.49585502688717)\n",
            "(('touted', 'today', 'at'), 10.49585502688717)\n",
            "(('Democracy', 'is', 'the'), 9.49585502688717)\n",
            "(('Selling', 'Your', 'Soul'), 9.49585502688717)\n",
            "(('Without', 'Selling', 'Your'), 9.49585502688717)\n",
            "(('Your', '60-second', 'guide'), 9.49585502688717)\n",
            "(('are', 'strangling', 'the'), 9.49585502688717)\n",
            "(('is', 'the', 'loser'), 9.49585502688717)\n",
            "(('loser', 'Your', '60-second'), 9.49585502688717)\n",
            "(('strangling', 'the', 'free'), 9.49585502688717)\n",
            "(('the', 'free', 'press'), 9.49585502688717)\n",
            "(('Google', 'and', 'Facebook'), 8.910892526166014)\n",
            "(('Google', 'touted', 'today'), 8.910892526166014)\n",
            "(('security', 'stuff', 'Google'), 8.910892526166014)\n",
            "(('stuff', 'Google', 'touted'), 8.910892526166014)\n",
            "(('60-second', 'guide', 'to'), 8.49585502688717)\n",
            "(('A', 'Guide', 'to'), 8.49585502688717)\n",
            "(('Guide', 'to', 'Using'), 8.49585502688717)\n",
            "(('free', 'press', 'to'), 8.49585502688717)\n",
            "(('guide', 'to', 'security'), 8.49585502688717)\n",
            "(('press', 'to', 'death'), 8.49585502688717)\n",
            "(('the', 'loser', 'Your'), 8.49585502688717)\n",
            "(('to', 'Using', 'Android'), 8.49585502688717)\n",
            "(('to', 'death', '.'), 8.49585502688717)\n",
            "(('to', 'security', 'stuff'), 8.49585502688717)\n",
            "(('Your', 'Soul', 'to'), 7.49585502688717)\n",
            "(('Soul', 'to', 'Google'), 6.910892526166014)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "u9NVPQyFTGQO"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Skipgram embedding"
      ],
      "metadata": {
        "id": "abbvP0QaR281"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Reference: https://github.com/nickvdw/word2vec-from-scratch/blob/master/word2vec.ipynb"
      ],
      "metadata": {
        "id": "7EfrvWI3W4Kb"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import keras.backend as K\n",
        "import tensorflow as tf\n",
        "import operator\n",
        "from tensorflow import keras\n",
        "from keras.utils import np_utils\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, Reshape, Lambda\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "from sklearn.metrics.pairwise import cosine_distances\n",
        "\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.neighbors import NearestNeighbors as nn\n",
        "from matplotlib import pylab\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "8z74dTO3khlz"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer(filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n'+\"'\")\n",
        "tokenizer.fit_on_texts(all_text)"
      ],
      "metadata": {
        "id": "3DzY18lXWOHQ"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = tokenizer.texts_to_sequences(all_text)\n",
        "n_samples = sum(len(s) for s in corpus) # Total number of words in the corpus\n",
        "V = len(tokenizer.word_index) + 1 # Total number of unique words in the corpus"
      ],
      "metadata": {
        "id": "NRjwjEgdV3nZ"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_samples, V"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5s9Sw28ZWImU",
        "outputId": "04f2cb6f-e732-476a-8b16-0fc5fd0f169e"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(152, 96)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example of how word to integer mapping looks like in the tokenizer\n",
        "print(list((tokenizer.word_index.items()))[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fh6BnYRFWWMP",
        "outputId": "242fb68a-6ec4-47c3-c314-724c2cd98c38"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('the', 1), ('is', 2), ('to', 3), ('a', 4), ('google', 5)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters\n",
        "window_size = 2 \n",
        "window_size_corpus = 4\n",
        "\n",
        "# Set numpy seed for reproducible results\n",
        "np.random.seed(42)"
      ],
      "metadata": {
        "id": "ptKeO2-GWf5u"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare data for the skipgram model\n",
        "def generate_data_skipgram(corpus, window_size, V):\n",
        "    maxlen = window_size * 2\n",
        "    all_in = []\n",
        "    all_out = []\n",
        "    for words in corpus:\n",
        "        L = len(words)\n",
        "        for index, word in enumerate(words):\n",
        "            p = index - window_size\n",
        "            n = index + window_size + 1\n",
        "\n",
        "            in_words = []\n",
        "            labels = []\n",
        "            for i in range(p, n):\n",
        "                if i != index and 0 <= i < L:\n",
        "                    # Add the input word\n",
        "                    all_in.append(word)\n",
        "                    # Add one-hot of the context words\n",
        "                    all_out.append(to_categorical(words[i], V))\n",
        "\n",
        "    return (np.array(all_in), np.array(all_out))"
      ],
      "metadata": {
        "id": "QtFMGm-bWjFS"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create training data\n",
        "X_skip, y_skip = generate_data_skipgram(corpus, window_size, V)\n",
        "X_skip.shape, y_skip.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L4cjpXwDWlV1",
        "outputId": "009734d4-bca1-4b67-b550-e5eefcf2e66e"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((530,), (530, 96))"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create skipgram architecture\n",
        "dims = [50, 150, 300]\n",
        "skipgram_models = []\n",
        "\n",
        "for dim in dims:\n",
        "    # Initialize a Keras Sequential model\n",
        "    skipgram = Sequential()\n",
        "\n",
        "    # Add an Embedding layer\n",
        "    skipgram.add(Embedding(input_dim=V, \n",
        "                           output_dim=dim, \n",
        "                           input_length=1, \n",
        "                           embeddings_initializer='glorot_uniform'))\n",
        "\n",
        "    # Add a Reshape layer, which reshapes the output of the embedding layer (1,dim) to (dim,)\n",
        "    skipgram.add(Reshape((dim, )))\n",
        "\n",
        "    # Add a final Dense layer with the same size as in [1]\n",
        "    skipgram.add(Dense(V, activation='softmax', kernel_initializer='glorot_uniform'))\n",
        "\n",
        "    # Compile the model with a suitable loss function and select an optimizer.\n",
        "    # Optimizer Adagrad was used in paper\n",
        "    skipgram.compile(optimizer=keras.optimizers.Adam(),\n",
        "                    loss='categorical_crossentropy',\n",
        "                    metrics=['accuracy'])\n",
        "    \n",
        "    skipgram.summary()\n",
        "    print(\"\")\n",
        "    skipgram_models.append(skipgram)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tUFfSTMGWm97",
        "outputId": "d51a15a2-52e2-48fb-e1e3-8bfe5557ef46"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 1, 50)             4800      \n",
            "                                                                 \n",
            " reshape (Reshape)           (None, 50)                0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 96)                4896      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 9,696\n",
            "Trainable params: 9,696\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (None, 1, 150)            14400     \n",
            "                                                                 \n",
            " reshape_1 (Reshape)         (None, 150)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 96)                14496     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 28,896\n",
            "Trainable params: 28,896\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_2 (Embedding)     (None, 1, 300)            28800     \n",
            "                                                                 \n",
            " reshape_2 (Reshape)         (None, 300)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 96)                28896     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 57,696\n",
            "Trainable params: 57,696\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the skipgram models\n",
        "for skipgram in skipgram_models:\n",
        "    skipgram.fit(X_skip, y_skip, batch_size=64, epochs=13, verbose=1)\n",
        "    print(\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SkpPIdTzWo1y",
        "outputId": "6e735dc5-4d46-44db-d3b6-b0fdaa6f35c6"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/13\n",
            "9/9 [==============================] - 1s 7ms/step - loss: 4.5691 - accuracy: 0.0113\n",
            "Epoch 2/13\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 4.5495 - accuracy: 0.0208\n",
            "Epoch 3/13\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.5335 - accuracy: 0.0283\n",
            "Epoch 4/13\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 4.5176 - accuracy: 0.0377\n",
            "Epoch 5/13\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.5019 - accuracy: 0.0453\n",
            "Epoch 6/13\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.4863 - accuracy: 0.0717\n",
            "Epoch 7/13\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 4.4704 - accuracy: 0.0755\n",
            "Epoch 8/13\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 4.4547 - accuracy: 0.0943\n",
            "Epoch 9/13\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 4.4385 - accuracy: 0.1019\n",
            "Epoch 10/13\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 4.4219 - accuracy: 0.1208\n",
            "Epoch 11/13\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 4.4053 - accuracy: 0.1321\n",
            "Epoch 12/13\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.3884 - accuracy: 0.1396\n",
            "Epoch 13/13\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 4.3708 - accuracy: 0.1528\n",
            "\n",
            "Epoch 1/13\n",
            "9/9 [==============================] - 1s 9ms/step - loss: 4.5725 - accuracy: 0.0057\n",
            "Epoch 2/13\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 4.5321 - accuracy: 0.0170\n",
            "Epoch 3/13\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.4989 - accuracy: 0.0434\n",
            "Epoch 4/13\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.4667 - accuracy: 0.0698\n",
            "Epoch 5/13\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.4347 - accuracy: 0.1019\n",
            "Epoch 6/13\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 4.4022 - accuracy: 0.1396\n",
            "Epoch 7/13\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.3692 - accuracy: 0.1736\n",
            "Epoch 8/13\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.3357 - accuracy: 0.1925\n",
            "Epoch 9/13\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.3010 - accuracy: 0.2075\n",
            "Epoch 10/13\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 4.2649 - accuracy: 0.2132\n",
            "Epoch 11/13\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.2271 - accuracy: 0.2113\n",
            "Epoch 12/13\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 4.1882 - accuracy: 0.2132\n",
            "Epoch 13/13\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 4.1479 - accuracy: 0.2094\n",
            "\n",
            "Epoch 1/13\n",
            "9/9 [==============================] - 1s 6ms/step - loss: 4.5644 - accuracy: 0.0170\n",
            "Epoch 2/13\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.5028 - accuracy: 0.0585\n",
            "Epoch 3/13\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 4.4515 - accuracy: 0.1132\n",
            "Epoch 4/13\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.4015 - accuracy: 0.1566\n",
            "Epoch 5/13\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 4.3517 - accuracy: 0.1755\n",
            "Epoch 6/13\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.3007 - accuracy: 0.1962\n",
            "Epoch 7/13\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.2481 - accuracy: 0.1981\n",
            "Epoch 8/13\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 4.1934 - accuracy: 0.2000\n",
            "Epoch 9/13\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.1350 - accuracy: 0.2000\n",
            "Epoch 10/13\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.0755 - accuracy: 0.2057\n",
            "Epoch 11/13\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.0121 - accuracy: 0.2075\n",
            "Epoch 12/13\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 3.9456 - accuracy: 0.2075\n",
            "Epoch 13/13\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 3.8769 - accuracy: 0.2057\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for skipgram in skipgram_models:\n",
        "    # Save embeddings for vectors of length 50, 150 and 300 using skipgram model\n",
        "    weights = skipgram.get_weights()\n",
        "\n",
        "    # Get the embedding matrix\n",
        "    embedding = weights[0]\n",
        "\n",
        "    # Get word embeddings for each word in the vocabulary, write to file\n",
        "    f = open(f\"vectors_skipgram_{len(embedding[0])}.txt\", \"w\")\n",
        "\n",
        "    # Create columns for the words and the values in the matrix, makes it easier to read as dataframe\n",
        "    columns = [\"word\"] + [f\"value_{i+1}\" for i in range(embedding.shape[1])]\n",
        "\n",
        "    # Start writing to the file, start with the column names\n",
        "    f.write(\" \".join(columns))\n",
        "\n",
        "    # Start a new line\n",
        "    f.write(\"\\n\")\n",
        "\n",
        "    for word, i in tokenizer.word_index.items():\n",
        "        f.write(word)\n",
        "        f.write(\" \")\n",
        "        f.write(\" \".join(map(str, list(embedding[i,:]))))\n",
        "        f.write(\"\\n\")\n",
        "    f.close()"
      ],
      "metadata": {
        "id": "GiRjEYndWrTS"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weights"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vnhr0R7JWwbC",
        "outputId": "306423df-8e9c-463b-d8d9-e0abd4d6a91c"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([[ 0.00062926, -0.02311563, -0.06231514, ..., -0.04720856,\n",
              "          0.00294507, -0.05793893],\n",
              "        [ 0.00037591,  0.06759916,  0.07356013, ..., -0.05931689,\n",
              "         -0.05297806,  0.03453358],\n",
              "        [-0.15343884,  0.15313508,  0.01244714, ..., -0.12911746,\n",
              "          0.04510623, -0.01036217],\n",
              "        ...,\n",
              "        [-0.05680786, -0.04049027,  0.06472202, ...,  0.14333192,\n",
              "         -0.01946976,  0.066402  ],\n",
              "        [-0.03266605, -0.05107694, -0.08680277, ..., -0.04681404,\n",
              "          0.01358245,  0.07512807],\n",
              "        [-0.11235233, -0.12496331, -0.11610719, ..., -0.05547908,\n",
              "          0.15627381,  0.14527903]], dtype=float32),\n",
              " array([[ 0.16008094, -0.10403235, -0.14997895, ..., -0.10233754,\n",
              "         -0.02826031, -0.0930145 ],\n",
              "        [-0.03626607,  0.01960105, -0.14457835, ..., -0.11606526,\n",
              "         -0.12537567,  0.00186577],\n",
              "        [-0.11205559, -0.04200958, -0.08245798, ..., -0.0937067 ,\n",
              "         -0.01436139,  0.06061462],\n",
              "        ...,\n",
              "        [ 0.1519396 ,  0.03956344,  0.05390424, ...,  0.12783042,\n",
              "         -0.06581921, -0.03308142],\n",
              "        [ 0.03601679,  0.05451855,  0.06304672, ...,  0.01422335,\n",
              "          0.13311824, -0.00314879],\n",
              "        [-0.0091775 ,  0.16836728,  0.12525037, ..., -0.07787258,\n",
              "         -0.03336115, -0.12431474]], dtype=float32),\n",
              " array([-0.10861062,  0.0987018 ,  0.09981922,  0.08415374,  0.09334055,\n",
              "         0.06639443,  0.05969164,  0.08706987,  0.0684026 ,  0.03842987,\n",
              "         0.05715334,  0.00991381,  0.01844234,  0.0085393 ,  0.02992994,\n",
              "        -0.01127534,  0.00292537,  0.00796829,  0.01715124,  0.01512384,\n",
              "        -0.01681587, -0.0378764 , -0.02787761, -0.01712412, -0.02393553,\n",
              "        -0.02792641, -0.03104826, -0.04677825, -0.08249421, -0.03995082,\n",
              "        -0.02961703, -0.03789588, -0.03347971, -0.0324431 , -0.03030619,\n",
              "        -0.03584367, -0.04421199, -0.06740727, -0.03214444, -0.02949402,\n",
              "        -0.02130688, -0.02603154, -0.07681446, -0.04961317, -0.02541268,\n",
              "        -0.03506638, -0.02204846, -0.0792385 , -0.04862717, -0.02972262,\n",
              "        -0.01301587, -0.02962638, -0.02887766, -0.03107795, -0.03150947,\n",
              "        -0.02397305, -0.02176171, -0.03028702, -0.03679199, -0.02911903,\n",
              "        -0.0324149 , -0.04770005, -0.07508863, -0.02387109, -0.01392705,\n",
              "        -0.03574846, -0.03532361, -0.03481288, -0.0254553 , -0.02708518,\n",
              "        -0.02979816, -0.03325049, -0.03554874, -0.07242595, -0.07473227,\n",
              "        -0.05058341, -0.03135797, -0.03624097, -0.04011446, -0.03035484,\n",
              "        -0.02633855, -0.03278086, -0.03345593, -0.07172274, -0.04725487,\n",
              "        -0.01794261, -0.02493024, -0.03043603, -0.03068864, -0.0580179 ,\n",
              "        -0.06346439, -0.02702165, -0.02729865, -0.02844316, -0.03341707,\n",
              "        -0.02133431], dtype=float32)]"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SEn969F2XWXN"
      },
      "execution_count": 31,
      "outputs": []
    }
  ]
}